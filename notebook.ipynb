{"cells":[{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"9d198ea1","execution_millis":27,"cell_id":"00000-32df7b6d-98fa-4417-842a-9889197ee3a0","execution_start":1603120590037},"source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (20,3)\n%config InlineBackend.figure_format='retina'","execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# How to Finally Ditch Spreadsheets in favour of Notebooks\n\nRecently, it is becoming more and more common to hear stories where excel seems to behave like it is haunted by some kind of ghosts: [human genes names are mistaken as dates ](https://www.theverge.com/2020/8/6/21355674/human-genes-rename-microsoft-excel-misreading-dates), \nlimits on the maximum number of rows simply [delete additional rows without warning the user](https://www.theguardian.com/politics/2020/oct/05/how-excel-may-have-caused-loss-of-16000-covid-tests-in-england), \nand it also happened that [someone lost around **6B$** for a spreadsheet error](https://www.businessinsider.com/excel-partly-to-blame-for-trading-loss-2013-2?IR=T).\n\n<img src='https://cdn.vox-cdn.com/thumbor/FmKvD1XuFdjxrvq2DBK9s0ZB3Ds=/1600x0/filters:no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/21700662/excel_gene_names_111.gif' height='200px'>\n\n## Introduction\n\nWhat it's slowly coming out is that when dealing with the so-called *big data*, AKA huge collections of data, usually containing more than 10K rows, spreadsheets are not the tool to go.\nThere are several limitations in many aspects, like the maximum number of rows and columns, auto-formatting which can lead to mistakes and, of course, \nsince spreadsheet is extremely widespread, different users having different literacies uses them, creating unpredictables situations, \nespecially when a situation escalates and the tool is the only tool used.\n\n<img src='./excel-limits.png' height='200px'>\n\nIn this article, I would like to show how to gradually switch from the spreadsheet in favour of modern notebooks, \ncloud storage, and how to performs most common spreadsheet operations using Python along with Pandas on a pretty heavy dataset.\n\nNowadays, there are many solutions out there that allow doing this: you can install [Jupyter](https://jupyter.org/),\nwork on [Colab](https://colab.research.google.com/) or use some hosted tools such as [Sagemaker](https://aws.amazon.com/sagemaker/). \nHowever, it is not always so straightforward to get started and plug everything together. That is the reason why, for this article, I will use [Deepnote](https://deepnote.com/), a free, hosted, and plug-n-play \nservice where you can run notebooks, have real-time collaboration, and natively access different databases.\n\n## The data\nThe dataset used in this article is the [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/olistbr/brazilian-ecommerce), \nit contains information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil. \nIts features allow viewing an order from multiple dimensions: from order status, price, payment and freight performance to customer location, product attributes and finally reviews written by customers.\n\nSince this dataset consists of nine different tables in `.csv` format it is helpful to have a schema of the dataset, AKA a *map* that helps us to understand \nhow tables are related to each other, giving the possibility to perform a different operation such as `VLOOKUP`, `SUMIF`, `CONCATENATE` and many others.\n\nYou can think of it as having different sheets related to each other.\n<img src='./data-schema.png' height='400px'>\n\n<!-- ## Loading the data\nThe tables are hosted on AWS S3, however, Deepnote has an extremely powerful integration to load data from S3, \nit is enough to add the integration, insert your bucket name and credentials, and *voit-la*, data available!\n<img src='./s3-card.png' height='150px'> -->\n\n## Loading the data\nThe tables can be uploaded into deepnote and are ready to be accesses, you can check that the data is correctly uploaded by executing the `ls` command:","metadata":{"tags":[],"output_cleared":false,"cell_id":"00001-03e2e283-a431-419e-8fe3-382308b72021"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"5545508","execution_millis":1515,"cell_id":"00002-6e3ada08-51c4-4b16-b0cf-3a6ad4a458b4","execution_start":1603120590162},"source":"!ls e-commerce-data","execution_count":23,"outputs":[{"name":"stdout","text":"olist_customers_dataset.csv\t  olist_orders_dataset.csv\r\nolist_geolocation_dataset.csv\t  olist_products_dataset.csv\r\nolist_order_items_dataset.csv\t  olist_sellers_dataset.csv\r\nolist_order_payments_dataset.csv  product_category_name_translation.csv\r\nolist_order_reviews_dataset.csv\r\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Answering business questions\nIn this section, a set business questions related to most the common KPIs and insights for an e-commerce are shown along with the code/solution to achieve it.\nMore precisely, we will answer question related to:\n\n- Total value of sales by the hour, day, week, or month.\n- Average value of transaction.\n- Where customers are based: it can be possible to identify where most customers are based and which are the most profitable cities.\n- Most ordered products.\n\n\n### Total value of sales\nThe goal of this question is to find out the total value of sales by the hour, day, week, and month.\nIt can be answered by grouping orders by the desired dimension and then the `SUM` function can be applied.\n\nTo answer this question we will need access to the timestamp (`order_purchase_timestamp`) when an order is created, and the value of the order. \nWe can achieve this by using two different tables: `olist_order_payments_dataset` and `olist_orders_dataset`, according to the database schema\nthe two tables can be joined together using the `order_id` column. Let's do this!","metadata":{"tags":[],"output_cleared":false,"cell_id":"00003-3c73984e-3828-4841-89c0-3d45e7ec4d40"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"997cad2d","execution_millis":1899,"cell_id":"00004-e1fb22fb-839a-4db1-b543-acfb05a73c38","execution_start":1603120591698},"source":"# load tables\norders = pd.read_csv('./e-commerce-data/olist_orders_dataset.csv')\norders_payments = pd.read_csv('./e-commerce-data/olist_order_payments_dataset.csv')","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"b9dc5fe1","execution_millis":206,"cell_id":"00005-c58c60c1-461c-488b-b5dc-f7f64146cdc0"},"source":"orders.info()","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"a2c533b","execution_millis":74,"cell_id":"00006-901df22b-97cc-49e4-a34d-d0567704461c"},"source":"orders_payments.info()","execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"However, after inspecting the dataset, I noticed the there is a column named `payment_installments`, meaning that the values in the `payment_value`\ncolumn are not reflecting the real order value. To have the real order value, we will have to multiply the number of instalments with the payment value. ","metadata":{"tags":[],"output_cleared":false,"cell_id":"00007-2ff9cc95-db39-4887-a264-130f498985e1"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"ab822812","execution_millis":316,"cell_id":"00008-3a84a8fc-9041-4e70-8e13-90f092279117"},"source":"# merged tables and convert timestamp to pandas-like format\norders_merged = orders.merge(orders_payments, how='inner', on='order_id')\norders_merged['order_purchase_timestamp'] = pd.to_datetime(orders_merged['order_purchase_timestamp'])","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"d5595c15","execution_millis":19,"cell_id":"00009-ed58d0c6-6bd2-4b86-9369-a20d451d4203"},"source":"# multiply the number of installments with the payment value\norders_merged['order_value'] = orders_merged['payment_value'] * orders_merged['payment_installments']","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"e6b888f4","execution_millis":860,"cell_id":"00010-b868ff11-0f17-4019-a578-a5ab8f5769f6"},"source":"# group by dimension and plot\n\norders_merged.groupby(orders_merged['order_purchase_timestamp'].dt.day)['order_value'].sum().plot()\nplt.title('Sales by day')","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"dac75753","execution_millis":789,"cell_id":"00011-20c66c92-ca9c-41dc-ad2b-fd4d54f5afa4"},"source":"orders_merged.groupby(orders_merged['order_purchase_timestamp'].dt.week)['order_value'].sum().plot()\n\nplt.title('Sales by week')","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"2c7a38ee","execution_millis":671,"cell_id":"00012-9d80994f-ac93-4746-a327-9779972ab58b"},"source":"orders_merged.groupby(orders_merged['order_purchase_timestamp'].dt.month)['order_value'].sum().plot()\nplt.title('Sales by month')","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Average value of a transaction\nThis KPI gives insights about how a typical shopping basked value evolves: from this is possible to understand if customers\ntend to buy multiple items in one order or rather have many small transactions. It is helpful when, for example, when architecting some promotions or discounts.\n\nTo achieve this we can use a strategy similar to the previous one: we will group transaction value by the month and get the average.","metadata":{"tags":[],"output_cleared":false,"cell_id":"00013-317a3bcc-9c73-475a-b030-45929cc8986b"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"34035f5b","execution_millis":113,"cell_id":"00014-5644cc92-ec11-479b-b79a-0f837a44da3a"},"source":"print('Average value of order by month')\navg_value = orders_merged.groupby(orders_merged['order_purchase_timestamp'].dt.month)['order_value'].mean().reset_index()\navg_value.columns = ['Month', 'Value']\n\navg_value = avg_value.round(2)\navg_value['Month'] = pd.to_datetime(avg_value['Month'], format='%m').dt.month_name().str.slice(stop=3)\n\navg_value","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Deepnote offers a really cool feature that lets you automatically plot data from a dataframe, just press on the \"visualize\" table inside the output section of a cell:","metadata":{"tags":[],"cell_id":"00015-0528e135-a124-42c3-b76e-3b54a307ec61","output_cleared":false}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"1fa46d86","execution_millis":84,"cell_id":"00016-d72101ab-58c5-4941-a172-f77b57a35d3f"},"source":"avg_value","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Where customers are based\nKnowing the location where a customer is based open the gates for many things: it is possible to understand which areas are more profitable than other, \nwhere our customers are based, and which regions/cities tend to spend more (or less) money on our platform.\n\nTo get the data ready we can, again, have a look at the schema: the `olist_customers_dataset` \ntable contains information customers geography. We can use this table and do some `groupby` along with `value_counts:`","metadata":{"tags":[],"output_cleared":false,"cell_id":"00017-ad1d94a9-579e-46de-805e-4f8798f15ea7"}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"4c32e213","execution_millis":348,"cell_id":"00018-56be9ce3-8643-40ad-aaff-b3b820478f67"},"source":"customers = pd.read_csv('e-commerce-data/olist_customers_dataset.csv')\ncustomers.head()","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"69fe247a","execution_millis":87,"cell_id":"00019-0d56035e-ca41-4639-9a68-cd29e5f007bf"},"source":"customers['customer_city'].value_counts().to_frame()","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"96b9f50a","execution_millis":1585,"cell_id":"00020-95f11ab8-bc60-4098-8069-4b17cacefd2f"},"source":"orders = pd.read_csv('e-commerce-data/olist_orders_dataset.csv')\norders.info()\n\nprint('\\n')\n\norder_items = pd.read_csv('e-commerce-data/olist_order_items_dataset.csv')\norder_items.info()","execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Most popular ordered products\nTo get this view it is necessary to merge the `olist_orders_dataset` with the `olist_order_items_dataset`, \nthe two tables can be joined using the `order_id` column. \nThen, similarly as before, it can be possible to count values of the `product_id` column. \nHowever, to get the item category, another join operation is needed: the item category name is stored inside the `olist_products_dataset`, \nwhich can be joined with `olist_order_items_dataset` using the `product_id` column.","metadata":{"tags":[],"cell_id":"00021-382c8328-7db5-42c5-95f9-2b3de8f09522","output_cleared":false}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"539d220d","execution_millis":315,"cell_id":"00022-06b60390-9536-4f00-a07f-125418620713"},"source":"orders_merged_items = orders.merge(order_items, how='inner', on='order_id')[['product_id']]\norders_merged_items.head()","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"613fb5c6","execution_millis":416,"cell_id":"00023-a94271b1-73e5-4e07-972d-a0614da85d55"},"source":"product_desc = pd.read_csv('e-commerce-data/olist_products_dataset.csv')\nproduct_desc.head()","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"543f3214","execution_millis":124,"cell_id":"00024-f5305b55-9523-466e-9ecf-6ce128ee538c"},"source":"# join orders_merged_items with product_desc on product_id column\nproduct_count = orders_merged_items.merge(product_desc, how='inner', on='product_id')\nproduct_count.head()","execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Everything seems to work well, however, product category names are in Portuguese, and not in English. \nLuckily the dataset comes with another table `product_category_name_translation` which, for every category name, the translated name in English. We can substitute the Portuguese column with the English one:","metadata":{"tags":[],"cell_id":"00025-7c7bb293-0051-4a94-888d-fec0392b6fa2","output_cleared":false}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"d9ca8396","execution_millis":61,"cell_id":"00026-d83a9f3f-3a05-490b-a760-5e776fa0b367"},"source":"eng_cat = pd.read_csv('e-commerce-data/product_category_name_translation.csv')\neng_cat.head()","execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"4c85fd27","execution_millis":125,"cell_id":"00027-52b96404-8745-4dd1-92ee-f14140dd5ffe"},"source":"product_count = product_count.merge(eng_cat)","execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"It is now possible to apply the `value_counts` function and plot the 20 most common categories:","metadata":{"tags":[],"cell_id":"00028-326b1b6c-494c-44f0-a0e7-83ca2021b081","output_cleared":false}},{"cell_type":"code","metadata":{"tags":[],"output_cleared":false,"source_hash":"8b534d47","execution_millis":810,"cell_id":"00029-b41cb417-2d58-40e9-b54f-d6a8eebee616"},"source":"product_count['product_category_name_english'].value_counts()[0:20].plot(kind='bar')","execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Where to go now?\nIn this short guide, I wanted to show some basic operation that could help you switch from the old-fashioned spreadsheet to\nnotebooks. Additional examples, tips and guides can be found in the [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html#intro-to-pandas)\ndocumentation. \n\nRegarding this dataset, in particular, I want to give you some starting points where you could expand this tutorial, for example, \nyou could use the the `olist_geolocation_dataset` along with the joined `olist_customers_dataset` and ` olist_orders_dataset` to create some heatmaps using [`gmaps`](https://jupyter-gmaps.readthedocs.io/en/v0.3.2/gmaps.html)\ndisplaying, for example, where the highest number of orders comes from, or where the average basket value is higher.\n\nMoreover, another good idea could be to create some sort of clustering model for customers, using variables such as the city a customer\ncomes from, the number of orders, the category of products the customers buys, and many more. Have a look at [this](https://levelup.gitconnected.com/unsupervised-learning-how-to-categorize-an-unlabelled-dataset-480fa2fdddd9) story to get ad idea.\n\nFeel free to copy this notebook, run it, or change it!\n[<img src='https://deepnote.com/buttons/launch-in-deepnote.svg'/>](https://deepnote.com/launch?template=deepnote&url=https%3A%2F%2Fgithub.com%2Frobertosannazzaro%2Fditch-spreadsheets-for-notebooks)","metadata":{"tags":[],"cell_id":"00030-cb134fc9-75b3-4d83-a223-5af8857ed989","output_cleared":false}}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"deepnote_notebook_id":"f29b3817-065a-4213-afdb-eb9894ab96ff","deepnote_execution_queue":[{"cellId":"00004-e1fb22fb-839a-4db1-b543-acfb05a73c38","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"a0f20d1e-00ee-40e2-b95f-c811c0aefdbd"},{"cellId":"00005-c58c60c1-461c-488b-b5dc-f7f64146cdc0","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"d55d0f41-0523-428d-afac-beb968f15f3f"},{"cellId":"00006-901df22b-97cc-49e4-a34d-d0567704461c","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"4df5d185-5ef7-4e93-9f0e-8b224a01738b"},{"cellId":"00008-3a84a8fc-9041-4e70-8e13-90f092279117","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"308cf8d7-3483-492f-97de-fb4c2e56ea73"},{"cellId":"00009-ed58d0c6-6bd2-4b86-9369-a20d451d4203","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"4e969377-6be1-45d0-bfd1-fb3b44e8cc73"},{"cellId":"00010-b868ff11-0f17-4019-a578-a5ab8f5769f6","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"6383f4a1-7baf-4256-a19a-99063a1ba116"},{"cellId":"00011-20c66c92-ca9c-41dc-ad2b-fd4d54f5afa4","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"baa88173-2f8a-4564-afe0-7a38ec2d53db"},{"cellId":"00012-9d80994f-ac93-4746-a327-9779972ab58b","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"21560cc0-c6cd-43cf-a7cf-28328e9bc1d0"},{"cellId":"00014-5644cc92-ec11-479b-b79a-0f837a44da3a","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"6a177d3b-105c-43a4-ae60-76c56d8f74a2"},{"cellId":"00016-d72101ab-58c5-4941-a172-f77b57a35d3f","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"96cc340d-2702-4a0e-985b-dbf4161767c9"},{"cellId":"00018-56be9ce3-8643-40ad-aaff-b3b820478f67","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"86854f43-adfc-4bb9-adf1-60b77722ed41"},{"cellId":"00019-0d56035e-ca41-4639-9a68-cd29e5f007bf","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"9cfcde05-68ab-47e3-9285-507e6f62354e"},{"cellId":"00020-95f11ab8-bc60-4098-8069-4b17cacefd2f","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"f1c683df-0d2d-4807-ba87-7ea8f59034c3"},{"cellId":"00022-06b60390-9536-4f00-a07f-125418620713","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"2c34bc64-2789-4e4c-8dc6-af1cf5e999ac"},{"cellId":"00023-a94271b1-73e5-4e07-972d-a0614da85d55","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"40026c1b-e1a4-443c-b2aa-a5eff1b987d6"},{"cellId":"00024-f5305b55-9523-466e-9ecf-6ce128ee538c","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"44056276-79ea-4808-8349-d184afe4fc10"},{"cellId":"00026-d83a9f3f-3a05-490b-a760-5e776fa0b367","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"57b7ebd4-44ce-44ba-b58f-0fbfd5a1efb7"},{"cellId":"00027-52b96404-8745-4dd1-92ee-f14140dd5ffe","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"3bc37b20-9f9e-4208-907a-db6a5a429f7d"},{"cellId":"00029-b41cb417-2d58-40e9-b54f-d6a8eebee616","sessionId":"fd8ee074-d828-4957-99fb-c2503ad03f39","msgId":"e724de40-b991-4c9e-ae9c-6f7b491b4123"}]}}